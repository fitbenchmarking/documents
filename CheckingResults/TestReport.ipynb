{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do we trust the FitBenchmarking results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: are the timings reproducible...\n",
    "\n",
    "### on the same machine?\n",
    "\n",
    "We ran the NIST tests on a virtual machine in the SCD Cloud on two occasions one day apart.  The machine was only used for benchmarking, with no other non-essential processes running.\n",
    "\n",
    "The accuracy plots produced were almost identical -- only Bumps' `de` method give different answers, but this is to be expected as it's a stochastic differential evolution algorithm.\n",
    "\n",
    "The time plots were very different -- so much so to suggest that, in it's current incarnation, FitBenchmarking shouldn't be used to compare times.  \n",
    "\n",
    "\n",
    "**Suggestions**:\n",
    "- run each example multiple (5?) times, and throw out the smallest and largest time\n",
    "- set a minimum time scale, and set the colour bars with respect to this.  For example, if you're not interested in differences less than 0.01s, set `rating = (time + 0.01) / (best + 0.01)`\n",
    "\n",
    "\n",
    "### on different machines?\n",
    "\n",
    "(not worth doing until we get somewhat reproducible results on the same machine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: are the results independent of the order of the minimizers?\n",
    "\n",
    "(not worth doing until we get reproducable results in the same order)\n",
    "\n",
    "### SciPy / Mantid / SasView swapped\n",
    "\n",
    "### Order inside a package swapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: are the timings in NIST/SciPy the same as we get if we run these examples outside of FitBenchmarking?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 4: do we get the $\\chi^2$ we expect for problems with a known solution?\n",
    "\n",
    "### Linear least-squares, non-weighted\n",
    "\n",
    "#### A consistent system\n",
    "\n",
    "We try to fit the coefficients of a cubic polynomial:\n",
    "$$f(\\boldsymbol{\\beta};\\mathbf{x}) = \\beta_1 + \\beta_2 x + \\beta_3 x^2 + \\beta_4 x^3, $$\n",
    "which reduces to solving the (linear) least-squares problem\n",
    "$$ \\boldsymbol{\\beta}^* = \\arg \\min_\\boldsymbol{\\beta} \\| \\mathbf{y} - A \\boldsymbol{\\beta}\\|_2^2, $$\n",
    "where $$A = \\begin{bmatrix} 1 & x_1 & x_1^2 & x_1^3 \\\\ \\vdots  & & & \\vdots \\\\ 1 & x_m & x_m^2 & x_m^3\\end{bmatrix}.$$\n",
    "\n",
    "We take $\\mathbf{x}$ to be 154 evenly spaced points between 1.0 and 5.0, and generate $\\mathbf{y}$ from the exact solution to the cubic polynomial with $\\boldsymbol{\\beta} = [ 4.0 \\ 3.0 \\ 2.0 \\ 1.0 ]$.\n",
    "\n",
    "This is encoded in `cubic.dat`\n",
    "\n",
    "#### An inconsistent system\n",
    "\n",
    "We try to solve the linear least squares problem\n",
    "$$ \\boldsymbol{\\beta}^* = \\arg \\min_\\boldsymbol{\\beta} \\| \\mathbf{y} - A \\boldsymbol{\\beta}\\|_2^2, $$\n",
    "where $\\mathbf{y}$ is the vector such that $y_i = 100.0$, and \n",
    "$$A = \\begin{bmatrix} \\cos(x_1) & \\sin(x_1) & x_1 \\\\ \\vdots  & & \\vdots \\\\ \\cos(x_m) & \\sin(x_m) & x_m \\end{bmatrix}.$$\n",
    "\n",
    "This has the solution \n",
    "$$\\beta = \\begin{bmatrix} 9.856883077249979 \\\\\n",
    " -17.383170262752689\\\\ \n",
    "  19.397333088483848 \\end{bmatrix},$$\n",
    "which has $\\chi^2 = 6.844347007091762$.\n",
    "\n",
    "This is encoded in `linear.dat`\n",
    "\n",
    "### Linear least-squares, weighted\n",
    "\n",
    "### Nonlinear least-squares, cubic polynomial, zero residual\n",
    "\n",
    "### Nonlinear least-squares, exponential\n",
    "\n",
    "#### Zero residual\n",
    "\n",
    "We solve the nonlinear least-squares problem\n",
    "$$ \\boldsymbol{\\beta}^* = \\arg \\min_\\boldsymbol{\\beta} \\sum \\left(y_i - \\beta_1 \\exp\\left(\\frac{-(\\beta_2 - x_i)^2}{\\beta_3^2}\\right)\\right)^2$$\n",
    "where $\\mathbf{x}$ is 101 uniformly distributed points between 0.0 and 5.0, and \n",
    "$$y_i = 10 *  \\exp\\left(\\frac{-(2.5 - x_i)^2}{4}\\right)$$,\n",
    "giving the exact solution $\\boldsymbol{\\beta} = [10.0 \\ 2.5 \\ 2.0]$.\n",
    "\n",
    "This is encoded in `exponential.dat`.\n",
    "\n",
    "#### non-zero residual\n",
    "\n",
    "We also have an example with the same data, but with noise added. The noise is \n",
    "$$\\mathbf{e} = \\mathtt{randn(101,1); \\mathbf{e} = \\frac{0.5}{\\|\\mathbf{e}\\|} \\mathbf{e}.$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
